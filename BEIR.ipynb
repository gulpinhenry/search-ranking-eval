{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzui28NKNKA1"
   },
   "source": [
    "# **BEIR: A Heterogenous benchmark for Zero-shot Evaluation of Information Retrieval models**\n",
    "\n",
    "This notebook contains an simple and easy examples to evaluate retrieval models from our new benchmark.\n",
    "\n",
    "## Introduction\n",
    "The BEIR benchmark contains 9 diverse retrieval tasks including 17 diverse datasets. We evaluate 9 state-of-the-art retriever models all in a zero-shot evaluation setup. Today, in this colab notebook, we first will show how to download and load the 14 open-sourced datasets with just three lines of code. Afterward, we would load some state-of-the-art dense retrievers (bi-encoders) such as SBERT, ANCE, DPR models and use them for retrieval and evaluate them in a zero-shot setup.\n",
    "\n",
    "Don't hesitate to send us an e-mail or report an issue, if something is broken (and it shouldn't be) or if you have further questions.\n",
    "\n",
    "Developed by Nandan Thakur, Researcher @ UKP Lab, TU Darmstadt\n",
    "\n",
    "(https://nthakur.xyz) (nandant@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWYQL2sJCKMi",
    "outputId": "1386acf1-a8fa-4d92-9d4d-446d768c5519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  6 14:59:31 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070      WDDM  |   00000000:07:00.0  On |                  N/A |\n",
      "| 30%   39C    P8             21W /  220W |    1695MiB /   8192MiB |     11%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1000    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A      1772    C+G   ...009.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A      4928    C+G   ...\\Local\\slack\\app-4.41.104\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A      5648    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     10480    C+G   ...\\Local\\slack\\app-4.41.104\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A     10700    C+G   ...ogram Files\\Unity Hub\\Unity Hub.exe      N/A      |\n",
      "|    0   N/A  N/A     11752    C+G   ...009.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A     11972    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12064    C+G   ...009.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A     14088    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     15752    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     17212    C+G   ...al\\Discord\\app-1.0.9173\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     18992    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A     19328    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     20204    C+G   ...on\\131.0.2903.70\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     22396    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     24820    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     25024    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     25432    C+G   ...6\\ServiceHub.ThreadedWaitDialog.exe      N/A      |\n",
      "|    0   N/A  N/A     25532    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     25660    C+G   ...22.1414_x64__rb9pth70m6nz6\\Muse.exe      N/A      |\n",
      "|    0   N/A  N/A     26556    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     29392    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     29776    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     33248    C+G   ...009.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "|    0   N/A  N/A     33324    C+G   ...19\\Community\\Common7\\IDE\\devenv.exe      N/A      |\n",
      "|    0   N/A  N/A     35896    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     36716    C+G   ...42.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     36784    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     37364    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     40260    C+G   ...009.0_x64__8wekyb3d8bbwe\\Photos.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qr9Ixc_X83IL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\beir\\util.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir import util, LoggingHandler\n",
    "\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G6hT73KOzfd"
   },
   "source": [
    "# **BEIR Datasets**\n",
    "\n",
    "BEIR contains 17 diverse datasets overall. You can view all the datasets (14 downloadable) with the link below:\n",
    "\n",
    "[``https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/``](https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/)\n",
    "\n",
    "Please refer GitHub page to evaluate on other datasets (3 of them).\n",
    "\n",
    "\n",
    "We include the following datasets in BEIR:\n",
    "\n",
    "| Dataset   | Website| BEIR-Name | Domain     | Relevancy| Queries  | Documents | Avg. Docs/Q | Download |\n",
    "| -------- | -----| ---------| ----------- | ---------| ---------| --------- | ------| ------------|\n",
    "| MSMARCO    | [``Homepage``](https://microsoft.github.io/msmarco/)| ``msmarco`` | Misc.       |  Binary  |  6,980   |  8.84M     |    1.1 | Yes |  \n",
    "| TREC-COVID |  [``Homepage``](https://ir.nist.gov/covidSubmit/index.html)| ``trec-covid``| Bio-Medical |  3-level|50|  171K| 493.5 | Yes |\n",
    "| NFCorpus   | [``Homepage``](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/) | ``nfcorpus``  | Bio-Medical |  3-level |  323     |  3.6K     |  38.2 | Yes |\n",
    "| BioASQ     | [``Homepage``](http://bioasq.org) | ``bioasq``| Bio-Medical |  Binary  |   500    |  14.91M    |  8.05 | No |\n",
    "| NQ         | [``Homepage``](https://ai.google.com/research/NaturalQuestions) | ``nq``| Wikipedia   |  Binary  |  3,452   |  2.68M  |  1.2 | Yes |\n",
    "| HotpotQA   | [``Homepage``](https://hotpotqa.github.io) | ``hotpotqa``| Wikipedia   |  Binary  |  7,405   |  5.23M  |  2.0 | Yes |\n",
    "| FiQA-2018  | [``Homepage``](https://sites.google.com/view/fiqa/) | ``fiqa``    | Finance     |  Binary  |  648     |  57K    |  2.6 | Yes |\n",
    "| Signal-1M (RT) | [``Homepage``](https://research.signal-ai.com/datasets/signal1m-tweetir.html)| ``signal1m`` | Twitter     |  3-level  |   97   |  2.86M  |  19.6 | No |\n",
    "| TREC-NEWS  | [``Homepage``](https://trec.nist.gov/data/news2019.html) | ``trec-news``    | News     |  5-level  |   57    |  595K    |  19.6 | No |\n",
    "| ArguAna    | [``Homepage``](http://argumentation.bplaced.net/arguana/data) | ``arguana`` | Misc.       |  Binary  |  1,406     |  8.67K    |  1.0 | Yes |\n",
    "| Touche-2020| [``Homepage``](https://webis.de/events/touche-20/shared-task-1.html) | ``webis-touche2020``| Misc.       |  6-level  |  49     |  382K    |  49.2 |  Yes |\n",
    "| CQADupstack| [``Homepage``](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/) | ``cqadupstack``| StackEx.      |  Binary  |  13,145 |  457K  |  1.4 |  Yes |\n",
    "| Quora| [``Homepage``](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs) | ``quora``| Quora  | Binary  |  10,000     |  523K    |  1.6 |  Yes |\n",
    "| DBPedia | [``Homepage``](https://github.com/iai-group/DBpedia-Entity/) | ``dbpedia-entity``| Wikipedia |  3-level  |  400    |  4.63M    |  38.2 |  Yes |\n",
    "| SCIDOCS| [``Homepage``](https://allenai.org/data/scidocs) | ``scidocs``| Scientific |  Binary  |  1,000     |  25K    |  4.9 |  Yes |\n",
    "| FEVER| [``Homepage``](http://fever.ai) | ``fever``| Wikipedia     |  Binary  |  6,666     |  5.42M    |  1.2|  Yes |\n",
    "| Climate-FEVER| [``Homepage``](http://climatefever.ai) | ``climate-fever``| Wikipedia |  Binary  |  1,535     |  5.42M |  3.0 |  Yes |\n",
    "| SciFact| [``Homepage``](https://github.com/allenai/scifact) | ``scifact``| Scientific |  Binary  |  300     |  5K    |  1.1 |  Yes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J26N5P_2jaQW"
   },
   "source": [
    "For Simplicity, we will show example with the one of the smallest datasets - ``SciFact`` for our example.\n",
    "\n",
    "You can evaluate any dataset you wish by looking at the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoNpMkclCyIt",
    "outputId": "46bf6fb2-dd09-4cf5-ec9d-32f9e2d6301c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 14:54:34 - Downloading msmarco.zip ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\search-ranking-eval\\eval\\datasets\\msmarco.zip: 100%|██████████| 1.01G/1.01G [03:18<00:00, 5.45MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 14:57:53 - Unzipping msmarco.zip ...\n",
      "Dataset downloaded here: d:\\Repos\\search-ranking-eval\\eval\\datasets\\msmarco\n"
     ]
    }
   ],
   "source": [
    "import pathlib, os\n",
    "from beir import util\n",
    "\n",
    "dataset = \"msmarco\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZpOAT0YQEJT"
   },
   "source": [
    "# **Folder Structure of any BEIR dataset**\n",
    "\n",
    "* scifact/\n",
    "    * corpus.jsonl\n",
    "    * queries.jsonl\n",
    "    * qrels/\n",
    "        * train.tsv\n",
    "        * dev.tsv\n",
    "        * test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeXB40loEI7y",
    "outputId": "5297f001-db4f-4778-96d7-58030ecb345b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.jsonl\n",
      "qrels\n",
      "queries.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls datasets/msmarco/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gB6I0UKeRH9-"
   },
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXORqILaEkSz",
    "outputId": "33746ef7-4583-42b7-c77b-3fb3e7707485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 14:59:50 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8841823/8841823 [00:47<00:00, 188000.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:00:54 - Loaded 8841823 TEST Documents.\n",
      "2024-12-06 15:00:57 - Doc Example: {'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 'title': ''}\n",
      "2024-12-06 15:00:57 - Loading Queries...\n",
      "2024-12-06 15:00:58 - Loaded 43 TEST Queries.\n",
      "2024-12-06 15:00:58 - Query Example: anthropological definition of environment\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "\n",
    "data_path = \"datasets/msmarco\"\n",
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTdflvK8RqMM"
   },
   "source": [
    "# **Dense Retrieval using Exact Search**\n",
    "\n",
    "## **Sentence-BERT**\n",
    "We use the [``distilbert-base-msmarco-v3``](https://www.sbert.net/docs/pretrained-models/msmarco-v3.html) SBERT model in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251,
     "referenced_widgets": [
      "e131bdb7a65c478c80e885fdd176c91d",
      "8d7f27371ce445079a7f4d967f509684",
      "d09db2ff674b49f68c56e0443e992d41",
      "cbc087909f8245ee88fed6acd02cad41",
      "c32f15946fba4fe286157a0986637496",
      "02e82d44f0de4ceea6d7a3fb6a386884",
      "98bb02dd10a44e18824bda49783e1f04",
      "96951650b0ea43319eed1c092a09d80c",
      "e1a77c1636ae43ceb0c93e9a57196d68",
      "da22bfc0bf924a6aa6094b50a0ca69ee",
      "ca5ad7176fec4d569e0dfca78f077961",
      "34ce6ee1956d4b93bf04fcf3bca0d195",
      "8af12510a59545e789896d6e409c9647",
      "cf2d1a5a1d3b45e8a66d599aa58914d8",
      "f3137b91d05d4cdcbfbd9e272da1c435",
      "61458551c1d741cabb19ac7b0231639a"
     ]
    },
    "id": "B2X_deOMFxJB",
    "outputId": "327beb86-4d8a-425d-bf2d-515986149c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:01:53 - PyTorch version 2.5.1 available.\n",
      "2024-12-06 15:01:54 - Loading faiss with AVX2 support.\n",
      "2024-12-06 15:01:54 - Successfully loaded faiss with AVX2 support.\n",
      "2024-12-06 15:01:54 - Use pytorch device_name: cpu\n",
      "2024-12-06 15:01:54 - Load pretrained SentenceTransformer: msmarco-distilbert-base-v3\n",
      "2024-12-06 15:01:59 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:01:59 - Sorting Corpus by document length (Longest first)...\n",
      "2024-12-06 15:02:42 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-12-06 15:02:42 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-12-06 15:02:42 - Encoding Batch 1/177...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 391/391 [48:35<00:00,  7.46s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:51:22 - Encoding Batch 2/177...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  23%|██▎       | 89/391 [09:43<32:58,  6.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m retriever \u001b[38;5;241m=\u001b[39m EvaluateRetrieval(model, score_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos_sim\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#### Retrieve dense results (format of results is identical to qrels)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\beir\\retrieval\\evaluation.py:20\u001b[0m, in \u001b[0;36mEvaluateRetrieval.retrieve\u001b[1;34m(self, corpus, queries, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel/Technique has not been provided!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\beir\\retrieval\\search\\dense\\exact_search.py:61\u001b[0m, in \u001b[0;36mDenseRetrievalExactSearch.search\u001b[1;34m(self, corpus, queries, top_k, score_function, return_sorted, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m corpus_end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(corpus_start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_chunk_size, \u001b[38;5;28mlen\u001b[39m(corpus))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Encode chunk of corpus    \u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m sub_corpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_corpus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorpus_start_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcorpus_end_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Compute similarites using either cosine-similarity or dot product\u001b[39;00m\n\u001b[0;32m     69\u001b[0m cos_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_functions[score_function](query_embeddings, sub_corpus_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\beir\\retrieval\\models\\sentence_bert.py:53\u001b[0m, in \u001b[0;36mSentenceBERT.encode_corpus\u001b[1;34m(self, corpus, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [(doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msep \u001b[38;5;241m+\u001b[39m doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01melse\u001b[39;00m doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus]\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[0;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[1;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:393\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m    391\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 393\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:798\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m    794\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask_for_sdpa(\n\u001b[0;32m    795\u001b[0m             attention_mask, embeddings\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    796\u001b[0m         )\n\u001b[1;32m--> 798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:551\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    543\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    544\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    545\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m         output_attentions,\n\u001b[0;32m    549\u001b[0m     )\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:477\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    486\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:391\u001b[0m, in \u001b[0;36mDistilBertSdpaAttention.forward\u001b[1;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"group heads\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m dim_per_head)\n\u001b[1;32m--> 391\u001b[0m q \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    392\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    393\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\henry\\miniconda3\\envs\\search-ranking-eval\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "#### Dense Retrieval using SBERT (Sentence-BERT) ####\n",
    "#### Provide any pretrained sentence-transformers model\n",
    "#### The model was fine-tuned using cosine-similarity.\n",
    "#### Complete list - https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "model = DRES(models.SentenceBERT(\"msmarco-distilbert-base-v3\"), batch_size=128)\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyC5x24k9ipJ",
    "outputId": "41885bf4-e69e-4825-9571-da593baa92a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 15:46:44 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2021-04-20 15:46:44 - \n",
      "\n",
      "2021-04-20 15:46:44 - NDCG@1: 0.4233\n",
      "2021-04-20 15:46:44 - NDCG@3: 0.4842\n",
      "2021-04-20 15:46:44 - NDCG@5: 0.5104\n",
      "2021-04-20 15:46:44 - NDCG@10: 0.5379\n",
      "2021-04-20 15:46:44 - NDCG@100: 0.5759\n",
      "2021-04-20 15:46:44 - NDCG@1000: 0.5913\n",
      "2021-04-20 15:46:44 - \n",
      "\n",
      "2021-04-20 15:46:44 - MAP@1: 0.3994\n",
      "2021-04-20 15:46:44 - MAP@3: 0.4593\n",
      "2021-04-20 15:46:44 - MAP@5: 0.4768\n",
      "2021-04-20 15:46:44 - MAP@10: 0.4889\n",
      "2021-04-20 15:46:44 - MAP@100: 0.4974\n",
      "2021-04-20 15:46:44 - MAP@1000: 0.4980\n",
      "2021-04-20 15:46:44 - \n",
      "\n",
      "2021-04-20 15:46:44 - Recall@1: 0.3994\n",
      "2021-04-20 15:46:44 - Recall@3: 0.5256\n",
      "2021-04-20 15:46:44 - Recall@5: 0.5887\n",
      "2021-04-20 15:46:44 - Recall@10: 0.6723\n",
      "2021-04-20 15:46:44 - Recall@100: 0.8460\n",
      "2021-04-20 15:46:44 - Recall@1000: 0.9683\n",
      "2021-04-20 15:46:44 - \n",
      "\n",
      "2021-04-20 15:46:44 - P@1: 0.4233\n",
      "2021-04-20 15:46:44 - P@3: 0.1933\n",
      "2021-04-20 15:46:44 - P@5: 0.1333\n",
      "2021-04-20 15:46:44 - P@10: 0.0757\n",
      "2021-04-20 15:46:44 - P@100: 0.0096\n",
      "2021-04-20 15:46:44 - P@1000: 0.0011\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "\n",
    "logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ak1ow4Qh_RxT",
    "outputId": "5d27e822-f469-48a3-8ae5-d6137006ac81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 15:57:32 - Query : Rapid up-regulation and higher basal expression of interferon-induced genes increase survival of granule cell neurons that are infected by West Nile virus.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 1: 7717468 [Loss of allergen 1 confers a hypervirulent phenotype that resembles mucoid switch variants of Cryptococcus neoformans.] - Microbial survival in a host is usually dependent on the ability of a pathogen to undergo changes that promote escape from host defense mechanisms. The human-pathogenic fungus Cryptococcus neoformans undergoes phenotypic switching in vivo that promotes persistence in tissue. By microarray and real-time PCR analyses, the allergen 1 gene (ALL1) was found to be downregulated in the hypervirulent mucoid switch variant, both during logarithmic growth and during intracellular growth in macrophages. The ALL1 gene encodes a small cytoplasmic protein that is involved in capsule formation. Growth of an all1Delta gene deletion mutant was normal. Similar to cells of the mucoid switch variant, all1Delta cells produced a larger polysaccharide capsule than cells of the smooth parent and the complemented strain produced, and the enlarged capsule inhibited macrophage phagocytosis. The mutant exhibited a modest defect in capsule induction compared to all of the other variants. In animal models the phenotype of the all1Delta mutant mimicked the hypervirulent phenotype of the mucoid switch variant, which is characterized by decreased host survival and elevated intracranial pressure. Decreased survival is likely the result of both an ineffective cell-mediated immune response and impaired phagocytosis by macrophages. Consequently, we concluded that, unlike loss of most virulence-associated genes, where loss of gene function results in attenuated virulence, loss of the ALL1 gene enhances virulence by altering the host-pathogen interaction and thereby impairing clearance. Our data identified the first cryptococcal gene associated with elevated intracranial pressure and support the hypothesis that an environmental opportunistic pathogen has modified its virulence in vivo by epigenetic downregulation of gene function.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 2: 10485142 [Molecular and cytogenetic changes involved in the immortalization of nasopharyngeal epithelial cells by telomerase.] - Nasopharyngeal carcinoma (NPC) is a common disease in Hong Kong and southern provinces of China. EBV infection is believed to play a critical role in the development of NPC. Previous studies on the transformation mechanism of EBV genes were mostly performed in either NPC or nonnasopharyngeal epithelial cells which may not be representative of premalignant nasopharyngeal epithelial cells. Establishment of a representative cell system would greatly facilitate the elucidation of the role of EBV infection in the development of NPC. Using telomerase alone, we were able to establish an immortalized nasopharyngeal epithelial cell line from primary nonmalignant nasopharyngeal biopsies. The telomerase-immortalized nasopharyngeal epithelial cells are largely diploid in karyotype. Interestingly, this newly immortalized nasopharyngeal epithelial cell line, referred as NP460hTert, harbors genetic alterations previously identified in premalignant and malignant nasopharyngeal epithelial cells. These include inactivation of p16 by homozygous deletion of the p16(INK4A) locus and downregulation of RASSF1A expression. The deletion of the p16(INK4A) locus appears to be the most crucial event for the immortalization of nasopharyngeal epithelial cells by telomerase and precedes RASSF1A downregulation. In addition, detailed analysis of the cytogenetic changes by conventional cytogenetics, spectral karyotyping (SKY) and array-based CGH revealed a gain of a 17q21-q25 fragment on 11p15 chromosome in all NP460hTert cells which occurred before deletion of the p16(INK4A) locus. Gain of 17q has been previously reported in NPC. In addition, activation of NF-kappaB was observed in immortalized NP460hTert cells at the later population doublings, and may play a role in the survival of immortalized NP epithelial cells. Id1 which is commonly expressed in various human cancers, including NPC, was also upregulated in the immortalized NP460hTert cells. Thus, the establishment of an immortalized nasopharyngeal epithelial cell line harboring common genetic alterations present in premalignant and cancerous nasopharyngeal epithelial cells may provide a valuable cell system to examine for early events involved in NPC carcinogenesis, particularly in elucidating the role of EBV infection in NPC development.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 3: 8671456 [Oncolytic adenovirus armed with IL-24 Inhibits the growth of breast cancer in vitro and in vivo] - BACKGROUND Interleukin-24 (IL-24) is a cytokine that belongs to the IL-10 family. It can selectively induce cancer cell apoptosis which has been utilized as a cancer gene therapy strategy. METHODS A recombinant type five adenovirus containing IL-24 gene (designated CNHK600-IL24) was constructed, whose replication is activated only in tumor cells. The replication of CNHK600-IL24 in breast tumor cells and fibroblasts were assessed by TCID50 and MTT assay; the secretion of IL-24 was measured by ELISA and western blotting. The in vivo anti-tumor effect of CNHK600-IL24 was investigated in nude mice carrying orthotopic or metastatic breast tumor. RESULTS We observed that CNHK600-IL24 could replicate efficiently and resulted in high level IL-24 expression and massive cell death in human breast cancer cell MDA-MB-231 but not in normal fibroblast cell MRC-5. In addition, orthotopic breast tumor growth in the nude mice model was significantly suppressed when CNHK600-IL24 was administered. In the metastatic model generated by tail vein injection, CNHK600-IL24 virotherapy significantly improved survival compared with the same virus expressing EGFP (median survival CNHK600-IL24, 55 days vs. CNHK600-EGFP, 41 day, p < 0.05 Mantal-Cox test). A similar phenomenon was observed in the metastatic model achieved by left ventricular injection as suggested by in vivo luminescence imaging of tumor growth. CONCLUSION The oncolytic adenovirus armed with IL-24, which exhibited enhanced anti-tumor activity and improved survival, is a promising candidate for virotherapy of breast cancer.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 4: 7155555 [Crucial Role of Interferon Consensus Sequence Binding Protein, but neither of Interferon Regulatory Factor 1 nor of Nitric Oxide Synthesis for Protection Against Murine Listeriosis] - Listeria monocytogenes is widely used as a model to study immune responses against intracellular bacteria. It has been shown that neutrophils and macrophages play an important role to restrict bacterial replication in the early phase of primary infection in mice, and that the cytokines interferon-γ (IFN-γ) and tumor necrosis factor-α (TNF-α) are essential for protection. However, the involved signaling pathways and effector mechanisms are still poorly understood. This study investigated mouse strains deficient for the IFN-dependent transcription factors interferon consensus sequence binding protein (ICSBP), interferon regulatory factor (IRF)1 or 2 for their capacity to eliminate Listeria in vivo and in vitro and for production of inducible reactive nitrogen intermediates (RNI) or reactive oxygen intermediates (ROI) in macrophages. ICSBP−/− and to a lesser degree also IRF2−/− mice were highly susceptible to Listeria infection. This correlated with impaired elimination of Listeria from infected peritoneal macrophage (PEM) cultures stimulated with IFN-γ in vitro; in addition these cultures showed reduced and delayed oxidative burst upon IFN-γ stimulation, whereas nitric oxide production was normal. In contrast, mice deficient for IRF1 were not able to produce nitric oxide, but they efficiently controlled Listeria in vivo and in vitro. These results indicate that (a) the ICSBP/IRF2 complex is essential for IFN-γ–mediated protection against Listeria and that (b) ROI together with additional still unknown effector mechanisms may be responsible for the anti-Listeria activity of macrophages, whereas IRF1-induced RNI are not limiting.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 5: 9433958 [Differential innate immune response programs in neuronal subtypes determine susceptibility to infection in the brain by positive stranded RNA viruses] - Although susceptibility of neurons in the brain to microbial infection is a major determinant of clinical outcome, little is known about the molecular factors governing this vulnerability. Here we show that two types of neurons from distinct brain regions showed differential permissivity to replication of several positive-stranded RNA viruses. Granule cell neurons of the cerebellum and cortical neurons from the cerebral cortex have unique innate immune programs that confer differential susceptibility to viral infection ex vivo and in vivo. By transducing cortical neurons with genes that were expressed more highly in granule cell neurons, we identified three interferon-stimulated genes (ISGs; Ifi27, Irg1 and Rsad2 (also known as Viperin)) that mediated the antiviral effects against different neurotropic viruses. Moreover, we found that the epigenetic state and microRNA (miRNA)-mediated regulation of ISGs correlates with enhanced antiviral response in granule cell neurons. Thus, neurons from evolutionarily distinct brain regions have unique innate immune signatures, which probably contribute to their relative permissiveness to infection.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 6: 10648422 [Programmed death-1–induced interleukin-10 production by monocytes impairs CD4+ T cell activation during HIV infection] - Viral replication and microbial translocation from the gut to the blood during HIV infection lead to hyperimmune activation, which contributes to the decline in CD4+ T cell numbers during HIV infection. Programmed death-1 (PD-1) and interleukin-10 (IL-10) are both upregulated during HIV infection. Blocking interactions between PD-1 and programmed death ligand-1 (PD-L1) and between IL-10 and IL-10 receptor (IL-10R) results in viral clearance and improves T cell function in animal models of chronic viral infections. Here we show that high amounts of microbial products and inflammatory cytokines in the plasma of HIV-infected subjects lead to upregulation of PD-1 expression on monocytes that correlates with high plasma concentrations of IL-10. Triggering of PD-1 expressed on monocytes by PD-L1 expressed on various cell types induced IL-10 production and led to reversible CD4+ T cell dysfunction. We describe a new function for PD-1 whereby microbial products inhibit T cell expansion and function by upregulating PD-1 levels and IL-10 production by monocytes after binding of PD-1 by PD-L1.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 7: 39545358 [Neuregulin 1 promotes excitatory synapse development and function in GABAergic interneurons.] - Neuregulin 1 (NRG1) and its receptor ErbB4 are both susceptibility genes of schizophrenia. However, little is known about the underlying mechanisms of their malfunction. Although ErbB4 is enriched in GABAergic interneurons, the role of NRG1 in excitatory synapse formation in these neurons remains poorly understood. We showed that NRG1 increased both the number and size of PSD-95 puncta and the frequency and amplitude of miniature EPSCs (mEPSCs) in GABAergic interneurons, indicating that NRG1 stimulates the formation of new synapses and strengthens existing synapses. In contrast, NRG1 treatment had no effect on either the number or size of excitatory synapses in glutamatergic neurons, suggesting its synaptogenic effect is specific to GABAergic interneurons. Ecto-ErbB4 treatment diminished both the number and size of excitatory synapses, suggesting that endogenous NRG1 may be critical for basal synapse formation. NRG1 could stimulate the stability of PSD-95 in the manner that requires tyrosine kinase activity of ErbB4. Finally, deletion of ErbB4 in parvalbumin-positive interneurons led to reduced frequency and amplitude of mEPSCs, providing in vivo evidence that ErbB4 is important in excitatory synaptogenesis in interneurons. Together, our findings suggested a novel synaptogenic role of NRG1 in excitatory synapse development, possibly via stabilizing PSD-95, and this effect is specific to GABAergic interneurons. In light of the association of the genes of both NRG1 and ErbB4 with schizophrenia and dysfunction of GABAergic system in this disorder, these results provide insight into its potential pathological mechanism.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 8: 5386514 [Activation of the NLRP3 inflammasome in dendritic cells induces IL-1β–dependent adaptive immunity against tumors] - The therapeutic efficacy of anticancer chemotherapies may depend on dendritic cells (DCs), which present antigens from dying cancer cells to prime tumor-specific interferon-γ (IFN-γ)–producing T lymphocytes. Here we show that dying tumor cells release ATP, which then acts on P2X7 purinergic receptors from DCs and triggers the NOD-like receptor family, pyrin domain containing-3 protein (NLRP3)-dependent caspase-1 activation complex ('inflammasome'), allowing for the secretion of interleukin-1β (IL-1β). The priming of IFN-γ–producing CD8+ T cells by dying tumor cells fails in the absence of a functional IL-1 receptor 1 and in Nlpr3-deficient (Nlrp3−/−) or caspase-1–deficient (Casp-1−/−) mice unless exogenous IL-1β is provided. Accordingly, anticancer chemotherapy turned out to be inefficient against tumors established in purinergic receptor P2rx7−/− or Nlrp3−/− or Casp1−/− hosts. Anthracycline-treated individuals with breast cancer carrying a loss-of-function allele of P2RX7 developed metastatic disease more rapidly than individuals bearing the normal allele. These results indicate that the NLRP3 inflammasome links the innate and adaptive immune responses against dying tumor cells.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 9: 6812319 [ERCC1 and MUS81–EME1 promote sister chromatid separation by processing late replication intermediates at common fragile sites during mitosis] - Chromosomal instability (CIN) is a hallmark of tumour initiation and progression. Some genomic regions are particularly unstable under replication stress, notably common fragile sites (CFSs) whose rearrangements in tumour cells contribute to cancer development. Recent work has shown that the Fanconi anaemia (FANC) pathway plays a role in preventing defective chromosome segregation and CIN under conditions of replication stress. Strikingly, FANCD2 is recruited to regions hosting CFSs on metaphase chromosomes. To decipher the mechanisms protecting CFSs in G2/M, we searched for proteins that co-localize with FANCD2 on mitotic chromosomes, and identified XPF–ERCC1 and MUS81–EME1, two structure-specific endonucleases. We show that depletion of either ERCC1 or MUS81–EME1 affects accurate processing of replication intermediates or under-replicated DNA that persist at CFSs until mitosis. Depletion of these endonucleases also leads to an increase in the frequency of chromosome bridges during anaphase that, in turn, favours accumulation of DNA damage in the following G1 phase.\n",
      "\n",
      "2021-04-20 15:57:32 - Rank 10: 7821634 [Profiling of residual breast cancers after neoadjuvant chemotherapy identifies DUSP4 deficiency as a mechanism of drug resistance] - Neoadjuvant chemotherapy (NAC) induces a pathological complete response (pCR) in ∼30% of patients with breast cancer. However, many patients have residual cancer after chemotherapy, which correlates with a higher risk of metastatic recurrence and poorer outcome than those who achieve a pCR. We hypothesized that molecular profiling of tumors after NAC would identify genes associated with drug resistance. Digital transcript counting was used to profile surgically resected breast cancers after NAC. Low concentrations of dual specificity protein phosphatase 4 (DUSP4), an ERK phosphatase, correlated with high post-NAC tumor cell proliferation and with basal-like breast cancer (BLBC) status. BLBC had higher DUSP4 promoter methylation and gene expression patterns of Ras-ERK pathway activation relative to other breast cancer subtypes. DUSP4 overexpression increased chemotherapy-induced apoptosis, whereas DUSP4 depletion dampened the response to chemotherapy. Reduced DUSP4 expression in primary tumors after NAC was associated with treatment-refractory high Ki-67 scores and shorter recurrence-free survival. Finally, inhibition of mitogen-activated protein kinase kinase (MEK) synergized with docetaxel treatment in BLBC xenografts. Thus, DUSP4 downregulation activates the Ras-ERK pathway in BLBC, resulting in an attenuated response to anti-cancer chemotherapy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#### Print top-k documents retrieved ####\n",
    "top_k = 10\n",
    "\n",
    "query_id, ranking_scores = random.choice(list(results.items()))\n",
    "scores_sorted = sorted(ranking_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "logging.info(\"Query : %s\\n\" % queries[query_id])\n",
    "\n",
    "for rank in range(top_k):\n",
    "    doc_id = scores_sorted[rank][0]\n",
    "    # Format: Rank x: ID [Title] Body\n",
    "    logging.info(\"Rank %d: %s [%s] - %s\\n\" % (rank+1, doc_id, corpus[doc_id].get(\"title\"), corpus[doc_id].get(\"text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMaqM0MSSZjy"
   },
   "source": [
    "## **ANCE**\n",
    "\n",
    "We use the [``msmarco-roberta-base-ance-fristp``](https://www.sbert.net/docs/pretrained-models/msmarco-v3.html) ANCE model which was fine-tuned on MSMARCO dataset for 600K steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "80af88ab84c94c86a317e741945fb007",
      "a995330792ae45358c576b0c5d2f66b7",
      "df04b30fa03b4b71ac8045e346b41d93",
      "36206923d4404d64b1fe98180c9b6e20",
      "c8ced75b6d4a48cd94ce424e985d8f00",
      "bdaeacfceb1f4e20a397e87353077cf3",
      "f39b5446bb0e4da3a7ef3a95d2ab0b69",
      "1c5fc15d1c2548ce9f37283eb3b06a50",
      "5fad24491a394799987a69b5a844923c",
      "9feca99a0eac4a67a4bc53e8b52793a2",
      "2ca6199ce63c4d2897ad8bf204103ca2",
      "8b001b35b123426682d1cf118147efe6",
      "642c76a148224e5eb82491d8385726e2",
      "6ddc45a220354d6aae30a2d85e81285f",
      "51e7407bf69d45038f306ae6863a7600",
      "a6e9327f4cb94bb68595f24c0c05ce81",
      "7bbaa89b27204404a33693df48348b0b",
      "fe53b820fc90428ea5f6b715c3051b7f",
      "279f940d093f4a5a85a71148350ecf0d",
      "4357165ed95742679cbcf8164a4a5eda",
      "9285c136f78c4c17af18b9bebd8e6bdc",
      "4b3d4d297c34468a87de10133ae65b70",
      "260fdeafc7ed47d993cebeef85b8a139",
      "51a95fbd92574e53a3283656c4767f8d"
     ]
    },
    "id": "GM4a02VKTZNj",
    "outputId": "ddf5edb0-ab4b-4fd7-e811-d6862d1e4c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 15:53:21 - Load pretrained SentenceTransformer: msmarco-roberta-base-ance-fristp\n",
      "2021-04-20 15:53:21 - Did not find folder msmarco-roberta-base-ance-fristp\n",
      "2021-04-20 15:53:21 - Search model on server: http://sbert.net/models/msmarco-roberta-base-ance-fristp.zip\n",
      "2021-04-20 15:53:21 - Downloading sentence transformer model from http://sbert.net/models/msmarco-roberta-base-ance-fristp.zip and saving it at /root/.cache/torch/sentence_transformers/sbert.net_models_msmarco-roberta-base-ance-fristp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80af88ab84c94c86a317e741945fb007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=464705670.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-04-20 15:53:44 - Load SentenceTransformer from folder: /root/.cache/torch/sentence_transformers/sbert.net_models_msmarco-roberta-base-ance-fristp\n",
      "2021-04-20 15:53:47 - Use pytorch device: cuda\n",
      "2021-04-20 15:53:47 - Encoding Queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fad24491a394799987a69b5a844923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=3.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-04-20 15:53:48 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2021-04-20 15:53:48 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbaa89b27204404a33693df48348b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=41.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Dense Retrieval using ANCE ####\n",
    "# https://www.sbert.net/docs/pretrained-models/msmarco-v3.html\n",
    "# MSMARCO Dev Passage Retrieval ANCE(FirstP) 600K model from ANCE.\n",
    "# The ANCE model was fine-tuned using dot-product (dot) function.\n",
    "\n",
    "model = DRES(models.SentenceBERT(\"msmarco-roberta-base-ance-fristp\"))\n",
    "retriever = EvaluateRetrieval(model, score_function=\"dot\")\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3toDuc__G6P",
    "outputId": "e8862904-8f17-4bde-a20a-fe0f5beeea30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 15:57:42 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2021-04-20 15:57:42 - \n",
      "\n",
      "2021-04-20 15:57:42 - NDCG@1: 0.4100\n",
      "2021-04-20 15:57:42 - NDCG@3: 0.4682\n",
      "2021-04-20 15:57:42 - NDCG@5: 0.4871\n",
      "2021-04-20 15:57:42 - NDCG@10: 0.5114\n",
      "2021-04-20 15:57:42 - NDCG@100: 0.5493\n",
      "2021-04-20 15:57:42 - NDCG@1000: 0.5665\n",
      "2021-04-20 15:57:42 - \n",
      "\n",
      "2021-04-20 15:57:42 - MAP@1: 0.3843\n",
      "2021-04-20 15:57:42 - MAP@3: 0.4416\n",
      "2021-04-20 15:57:42 - MAP@5: 0.4546\n",
      "2021-04-20 15:57:42 - MAP@10: 0.4661\n",
      "2021-04-20 15:57:42 - MAP@100: 0.4732\n",
      "2021-04-20 15:57:42 - MAP@1000: 0.4738\n",
      "2021-04-20 15:57:42 - \n",
      "\n",
      "2021-04-20 15:57:42 - Recall@1: 0.3843\n",
      "2021-04-20 15:57:42 - Recall@3: 0.5124\n",
      "2021-04-20 15:57:42 - Recall@5: 0.5613\n",
      "2021-04-20 15:57:42 - Recall@10: 0.6333\n",
      "2021-04-20 15:57:42 - Recall@100: 0.8187\n",
      "2021-04-20 15:57:42 - Recall@1000: 0.9567\n",
      "2021-04-20 15:57:42 - \n",
      "\n",
      "2021-04-20 15:57:42 - P@1: 0.4100\n",
      "2021-04-20 15:57:42 - P@3: 0.1889\n",
      "2021-04-20 15:57:42 - P@5: 0.1260\n",
      "2021-04-20 15:57:42 - P@10: 0.0720\n",
      "2021-04-20 15:57:42 - P@100: 0.0093\n",
      "2021-04-20 15:57:42 - P@1000: 0.0011\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "\n",
    "logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqotyXuIBPt6"
   },
   "source": [
    "# **Lexical Retrieval using BM25 (Elasticsearch)**\n",
    "\n",
    "## 1. Download and setup the Elasticsearch instance\n",
    "Reference: https://colab.research.google.com/github/tensorflow/io/blob/master/docs/tutorials/elasticsearch.ipynb\n",
    "\n",
    "For demo purposes, the open-source version of the elasticsearch package is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doQU8m_UBFOY",
    "outputId": "573d2b28-2f63-4d4b-a379-0cfda1c3a4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
    "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
    "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
    "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
    "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DruoaeGPBxg0"
   },
   "source": [
    "Run the instance as a daemon process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVZCVh-VBFDg",
    "outputId": "d6957943-6dd4-47a4-935c-d5d1cb4d708f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%bash --bg\n",
    "\n",
    "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6A3xsNtBE6B"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Sleep for few seconds to let the instance start.\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zLrT3zNCAoW"
   },
   "source": [
    "Once the instance has been started, grep for ``elasticsearch`` in the processes list to confirm the availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pz84EzxmBEmV",
    "outputId": "e70f7559-b065-4dc6-9af6-098e41ed5f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root         664     662  0 16:05 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch\n",
      "daemon       665     664 23 16:05 ?        00:00:16 /content/elasticsearch-7.9.2/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-1430391873797249845 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=data -XX:ErrorFile=logs/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/content/elasticsearch-7.9.2 -Des.path.conf=/content/elasticsearch-7.9.2/config -Des.distribution.flavor=oss -Des.distribution.type=tar -Des.bundled_jdk=true -cp /content/elasticsearch-7.9.2/lib/* org.elasticsearch.bootstrap.Elasticsearch\n",
      "root         906     904  0 16:06 ?        00:00:00 grep elasticsearch\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ps -ef | grep elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6ASWFOGCLEm",
    "outputId": "c762129f-cf95-46b8-97fa-6c541ae18dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"c0f3c0cd00cc\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"RjQ4yenrQomacpABczxITQ\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"7.9.2\",\n",
      "    \"build_flavor\" : \"oss\",\n",
      "    \"build_type\" : \"tar\",\n",
      "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
      "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"8.6.2\",\n",
      "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -sX GET \"localhost:9200/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqP2F4IKCloh",
    "outputId": "c626234b-dcd8-4fd9-84a1-266d8fc7bc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 16:09:45 - Activating Elasticsearch....\n",
      "2021-04-20 16:09:45 - Elastic Search Credentials: {'hostname': 'localhost', 'index_name': 'scifact', 'keys': {'title': 'title', 'body': 'txt'}, 'timeout': 100, 'retry_on_timeout': True, 'maxsize': 24}\n",
      "2021-04-20 16:09:45 - Deleting previous Elasticsearch-Index named - scifact\n",
      "2021-04-20 16:09:45 - Creating fresh Elasticsearch-Index named - scifact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5183 [00:00<?, ?docs/s]        \n",
      "que: 100%|██████████| 3/3 [00:14<00:00,  4.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "#### Provide parameters for elastic-search\n",
    "hostname = \"localhost\"\n",
    "index_name = \"scifact\"\n",
    "initialize = True # True, will delete existing index with same name and reindex all documents\n",
    "\n",
    "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
    "retriever = EvaluateRetrieval(model)\n",
    "\n",
    "#### Retrieve dense results (format of results is identical to qrels)\n",
    "results = retriever.retrieve(corpus, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJcCpUCFClis",
    "outputId": "c5ae7611-5ae4-4e42-86db-4c329e8e5ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 16:10:20 - \n",
      "\n",
      "2021-04-20 16:10:20 - NDCG@1: 0.5400\n",
      "2021-04-20 16:10:20 - NDCG@3: 0.6104\n",
      "2021-04-20 16:10:20 - NDCG@5: 0.6297\n",
      "2021-04-20 16:10:20 - NDCG@10: 0.6495\n",
      "2021-04-20 16:10:20 - NDCG@100: 0.6749\n",
      "2021-04-20 16:10:20 - NDCG@1000: 0.6850\n",
      "2021-04-20 16:10:20 - \n",
      "\n",
      "2021-04-20 16:10:20 - MAP@1: 0.5176\n",
      "2021-04-20 16:10:20 - MAP@3: 0.5851\n",
      "2021-04-20 16:10:20 - MAP@5: 0.5974\n",
      "2021-04-20 16:10:20 - MAP@10: 0.6068\n",
      "2021-04-20 16:10:20 - MAP@100: 0.6130\n",
      "2021-04-20 16:10:20 - MAP@1000: 0.6134\n",
      "2021-04-20 16:10:20 - \n",
      "\n",
      "2021-04-20 16:10:20 - Recall@1: 0.5176\n",
      "2021-04-20 16:10:20 - Recall@3: 0.6607\n",
      "2021-04-20 16:10:20 - Recall@5: 0.7071\n",
      "2021-04-20 16:10:20 - Recall@10: 0.7657\n",
      "2021-04-20 16:10:20 - Recall@100: 0.8742\n",
      "2021-04-20 16:10:20 - Recall@1000: 0.9550\n",
      "2021-04-20 16:10:20 - \n",
      "\n",
      "2021-04-20 16:10:20 - P@1: 0.5400\n",
      "2021-04-20 16:10:20 - P@3: 0.2356\n",
      "2021-04-20 16:10:20 - P@5: 0.1547\n",
      "2021-04-20 16:10:20 - P@10: 0.0840\n",
      "2021-04-20 16:10:20 - P@100: 0.0099\n",
      "2021-04-20 16:10:20 - P@1000: 0.0011\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfiEjuXAATkZ"
   },
   "source": [
    "# **Reranking BM25 using Cross-Encoder**\n",
    "\n",
    "In this example, we rerank the top-20 documents retrieved from BM25, using ([cross-encoder/ms-marco-electra-base](https://www.sbert.net/docs/pretrained-models/ce-msmarco.html)) SBERT cross-encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "022256eee56f4d6fb6a8e595426296fc",
      "4cfe0ecadaff4f3eb0e219570ebdb9a8",
      "a89266c1a2a44215922242a145e5f697",
      "4ae2dd4354a744d5a643967aba01946c",
      "5b6677b79ba6436b97773d68602d09b7",
      "143940feda034ae9bb0fecfd2d280f16",
      "8cdb93401e0847d99677be35d75f80f2",
      "d23c27d7b9e24fa6a98c990d80e9bc6e"
     ]
    },
    "id": "ILM1SNXdAGhn",
    "outputId": "8cdc9b51-cd3b-4b6b-d016-efba409a05cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 16:14:39 - Use pytorch device: cuda\n",
      "2021-04-20 16:14:39 - Starting To Rerank Top-20....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022256eee56f4d6fb6a8e595426296fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=47.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from beir.reranking.models import CrossEncoder\n",
    "from beir.reranking import Rerank\n",
    "\n",
    "#### Reranking using Cross-Encoder models (list: )\n",
    "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-electra-base')\n",
    "reranker = Rerank(cross_encoder_model, batch_size=128)\n",
    "\n",
    "# Rerank top-100 results using the reranker provided\n",
    "rerank_results = reranker.rerank(corpus, queries, results, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tC2L6VWtAS5J",
    "outputId": "282f1c2e-e5b2-494b-ed8d-7890e166f8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 16:19:08 - \n",
      "\n",
      "2021-04-20 16:19:08 - NDCG@1: 0.5733\n",
      "2021-04-20 16:19:08 - NDCG@3: 0.6314\n",
      "2021-04-20 16:19:08 - NDCG@5: 0.6520\n",
      "2021-04-20 16:19:08 - NDCG@10: 0.6720\n",
      "2021-04-20 16:19:08 - NDCG@100: 0.6780\n",
      "2021-04-20 16:19:08 - NDCG@1000: 0.6780\n",
      "2021-04-20 16:19:08 - \n",
      "\n",
      "2021-04-20 16:19:08 - MAP@1: 0.5451\n",
      "2021-04-20 16:19:08 - MAP@3: 0.6074\n",
      "2021-04-20 16:19:08 - MAP@5: 0.6216\n",
      "2021-04-20 16:19:08 - MAP@10: 0.6307\n",
      "2021-04-20 16:19:08 - MAP@100: 0.6324\n",
      "2021-04-20 16:19:08 - MAP@1000: 0.6324\n",
      "2021-04-20 16:19:08 - \n",
      "\n",
      "2021-04-20 16:19:08 - Recall@1: 0.5451\n",
      "2021-04-20 16:19:08 - Recall@3: 0.6758\n",
      "2021-04-20 16:19:08 - Recall@5: 0.7260\n",
      "2021-04-20 16:19:08 - Recall@10: 0.7844\n",
      "2021-04-20 16:19:08 - Recall@100: 0.8078\n",
      "2021-04-20 16:19:08 - Recall@1000: 0.8078\n",
      "2021-04-20 16:19:08 - \n",
      "\n",
      "2021-04-20 16:19:08 - P@1: 0.5733\n",
      "2021-04-20 16:19:08 - P@3: 0.2444\n",
      "2021-04-20 16:19:08 - P@5: 0.1613\n",
      "2021-04-20 16:19:08 - P@10: 0.0880\n",
      "2021-04-20 16:19:08 - P@100: 0.0090\n",
      "2021-04-20 16:19:08 - P@1000: 0.0009\n"
     ]
    }
   ],
   "source": [
    "#### Evaluate your retrieval using NDCG@k, MAP@K ...\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(qrels, rerank_results, retriever.k_values)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "search-ranking-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "022256eee56f4d6fb6a8e595426296fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a89266c1a2a44215922242a145e5f697",
       "IPY_MODEL_4ae2dd4354a744d5a643967aba01946c"
      ],
      "layout": "IPY_MODEL_4cfe0ecadaff4f3eb0e219570ebdb9a8"
     }
    },
    "02e82d44f0de4ceea6d7a3fb6a386884": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "143940feda034ae9bb0fecfd2d280f16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c5fc15d1c2548ce9f37283eb3b06a50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "260fdeafc7ed47d993cebeef85b8a139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "279f940d093f4a5a85a71148350ecf0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b3d4d297c34468a87de10133ae65b70",
      "max": 41,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9285c136f78c4c17af18b9bebd8e6bdc",
      "value": 41
     }
    },
    "2ca6199ce63c4d2897ad8bf204103ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ddc45a220354d6aae30a2d85e81285f",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_642c76a148224e5eb82491d8385726e2",
      "value": 3
     }
    },
    "34ce6ee1956d4b93bf04fcf3bca0d195": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61458551c1d741cabb19ac7b0231639a",
      "placeholder": "​",
      "style": "IPY_MODEL_f3137b91d05d4cdcbfbd9e272da1c435",
      "value": " 41/41 [29:03&lt;00:00, 42.52s/it]"
     }
    },
    "36206923d4404d64b1fe98180c9b6e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5fc15d1c2548ce9f37283eb3b06a50",
      "placeholder": "​",
      "style": "IPY_MODEL_f39b5446bb0e4da3a7ef3a95d2ab0b69",
      "value": " 465M/465M [00:22&lt;00:00, 20.7MB/s]"
     }
    },
    "4357165ed95742679cbcf8164a4a5eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51a95fbd92574e53a3283656c4767f8d",
      "placeholder": "​",
      "style": "IPY_MODEL_260fdeafc7ed47d993cebeef85b8a139",
      "value": " 41/41 [20:07&lt;00:00, 29.46s/it]"
     }
    },
    "4ae2dd4354a744d5a643967aba01946c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d23c27d7b9e24fa6a98c990d80e9bc6e",
      "placeholder": "​",
      "style": "IPY_MODEL_8cdb93401e0847d99677be35d75f80f2",
      "value": " 47/47 [04:19&lt;00:00,  5.52s/it]"
     }
    },
    "4b3d4d297c34468a87de10133ae65b70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cfe0ecadaff4f3eb0e219570ebdb9a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51a95fbd92574e53a3283656c4767f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51e7407bf69d45038f306ae6863a7600": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b6677b79ba6436b97773d68602d09b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5fad24491a394799987a69b5a844923c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ca6199ce63c4d2897ad8bf204103ca2",
       "IPY_MODEL_8b001b35b123426682d1cf118147efe6"
      ],
      "layout": "IPY_MODEL_9feca99a0eac4a67a4bc53e8b52793a2"
     }
    },
    "61458551c1d741cabb19ac7b0231639a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642c76a148224e5eb82491d8385726e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6ddc45a220354d6aae30a2d85e81285f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bbaa89b27204404a33693df48348b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_279f940d093f4a5a85a71148350ecf0d",
       "IPY_MODEL_4357165ed95742679cbcf8164a4a5eda"
      ],
      "layout": "IPY_MODEL_fe53b820fc90428ea5f6b715c3051b7f"
     }
    },
    "80af88ab84c94c86a317e741945fb007": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df04b30fa03b4b71ac8045e346b41d93",
       "IPY_MODEL_36206923d4404d64b1fe98180c9b6e20"
      ],
      "layout": "IPY_MODEL_a995330792ae45358c576b0c5d2f66b7"
     }
    },
    "8af12510a59545e789896d6e409c9647": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8b001b35b123426682d1cf118147efe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6e9327f4cb94bb68595f24c0c05ce81",
      "placeholder": "​",
      "style": "IPY_MODEL_51e7407bf69d45038f306ae6863a7600",
      "value": " 3/3 [00:54&lt;00:00, 18.31s/it]"
     }
    },
    "8cdb93401e0847d99677be35d75f80f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d7f27371ce445079a7f4d967f509684": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9285c136f78c4c17af18b9bebd8e6bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "96951650b0ea43319eed1c092a09d80c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98bb02dd10a44e18824bda49783e1f04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9feca99a0eac4a67a4bc53e8b52793a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e9327f4cb94bb68595f24c0c05ce81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a89266c1a2a44215922242a145e5f697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_143940feda034ae9bb0fecfd2d280f16",
      "max": 47,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b6677b79ba6436b97773d68602d09b7",
      "value": 47
     }
    },
    "a995330792ae45358c576b0c5d2f66b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdaeacfceb1f4e20a397e87353077cf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c32f15946fba4fe286157a0986637496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c8ced75b6d4a48cd94ce424e985d8f00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ca5ad7176fec4d569e0dfca78f077961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf2d1a5a1d3b45e8a66d599aa58914d8",
      "max": 41,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8af12510a59545e789896d6e409c9647",
      "value": 41
     }
    },
    "cbc087909f8245ee88fed6acd02cad41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96951650b0ea43319eed1c092a09d80c",
      "placeholder": "​",
      "style": "IPY_MODEL_98bb02dd10a44e18824bda49783e1f04",
      "value": " 3/3 [00:14&lt;00:00,  4.73s/it]"
     }
    },
    "cf2d1a5a1d3b45e8a66d599aa58914d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d09db2ff674b49f68c56e0443e992d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02e82d44f0de4ceea6d7a3fb6a386884",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c32f15946fba4fe286157a0986637496",
      "value": 3
     }
    },
    "d23c27d7b9e24fa6a98c990d80e9bc6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da22bfc0bf924a6aa6094b50a0ca69ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df04b30fa03b4b71ac8045e346b41d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdaeacfceb1f4e20a397e87353077cf3",
      "max": 464705670,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8ced75b6d4a48cd94ce424e985d8f00",
      "value": 464705670
     }
    },
    "e131bdb7a65c478c80e885fdd176c91d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d09db2ff674b49f68c56e0443e992d41",
       "IPY_MODEL_cbc087909f8245ee88fed6acd02cad41"
      ],
      "layout": "IPY_MODEL_8d7f27371ce445079a7f4d967f509684"
     }
    },
    "e1a77c1636ae43ceb0c93e9a57196d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca5ad7176fec4d569e0dfca78f077961",
       "IPY_MODEL_34ce6ee1956d4b93bf04fcf3bca0d195"
      ],
      "layout": "IPY_MODEL_da22bfc0bf924a6aa6094b50a0ca69ee"
     }
    },
    "f3137b91d05d4cdcbfbd9e272da1c435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f39b5446bb0e4da3a7ef3a95d2ab0b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe53b820fc90428ea5f6b715c3051b7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
